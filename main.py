import os
import subprocess
import shlex
import time
from dotenv import load_dotenv
from crewai import Agent, Task, Crew, Process
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_anthropic import ChatAnthropic
from langchain_openai import ChatOpenAI
from crewai_tools import BaseTool
import sys

# --- Outils ---
class SecureCommandLineTool(BaseTool):
    name: str = "SecureTerminal"
    description: str = "Ex√©cute des commandes shell s√©curis√©es pour construire et valider le projet."
    ALLOWED_COMMANDS = ['mkdir', 'echo', 'cat', 'ls', 'npm', 'node', 'git', 'touch', 'npx', 'timeout', 'curl', 'sleep', 'kill']
    
    def _run(self, command: str) -> str:
        try:
            # L'utilisation de shell=True est n√©cessaire pour les pipes et les cha√Ænages,
            # la s√©curit√© est assur√©e par la whitelist.
            result = subprocess.run(command, shell=True, capture_output=True, text=True, check=True, timeout=300)
            return f"‚úÖ Commande ex√©cut√©e avec succ√®s.\n{result.stdout}"
        except Exception as e:
            return f"‚ùå ERREUR lors de l'ex√©cution de '{command}': {e}"

class EnhancedProjectTemplateManager(BaseTool):
    name: str = "ProjectTemplateManager"
    description: str = "G√©n√®re les commandes de base pour la structure et le contenu initial du projet."
    
    def _run(self, template_name: str, project_name: str) -> str:
        base_templates = {
            'webapp-basic': [
                f'mkdir -p workspace/{project_name}/frontend',
                f'mkdir -p workspace/{project_name}/backend',
                f'cd workspace/{project_name}/frontend && npm create vite@latest . -- --template react',
                f'cd workspace/{project_name}/backend && npm init -y && npm install express cors dotenv',
                f'cd workspace/{project_name} && echo "node_modules/\n.env\nbuild/\ndist/" > .gitignore',
                f'cd workspace/{project_name} && echo "# {project_name}\n\nProjet g√©n√©r√© par l\'Agent IA V17." > README.md'
            ]
        }
        commands = base_templates.get(template_name, [])
        if not commands: return f"‚ùå Template '{template_name}' non trouv√©."
        return "Commandes de cr√©ation de squelette g√©n√©r√©es:\n" + "\n".join(commands)

# --- Interface Utilisateur ---
class ProjectSelector:
    def select_template(self) -> tuple[str, str]:
        # Support CLI arguments pour API
        if len(sys.argv) >= 2:
            project_name = sys.argv[1]
            print(f"\n‚úÖ G√©n√©ration d'une application fonctionnelle nomm√©e '{project_name}'...")
            return "webapp-basic", project_name
        
        # Fallback interactif (comportement original)
        print("\n" + "="*60 + "\nüöÄ G√âN√âRATEUR D'APPLICATIONS IA - v17\n" + "="*60)
        project_name = input("Nom du projet: ").strip() or "my-functional-app-v17"
        print(f"\n‚úÖ G√©n√©ration d'une application fonctionnelle nomm√©e '{project_name}'...")
        return "webapp-basic", project_name

# --- Point d'Entr√©e Principal ---
def main():
    load_dotenv()
    required_keys = ["GOOGLE_API_KEY", "ANTHROPIC_API_KEY", "OPENAI_API_KEY"]
    for key in required_keys:
        if not os.getenv(key):
            raise ValueError(f"Cl√© manquante dans .env : {key}")

    selector = ProjectSelector()
    template_type, project_name = selector.select_template()

    if not os.path.exists('./workspace'): os.makedirs('./workspace')

    llms = {
        "claude": ChatAnthropic(model="claude-opus-4-20250514"),
        "gemini": ChatGoogleGenerativeAI(model="gemini-1.5-pro"),
        "openai": ChatOpenAI(model="gpt-4o-mini")
    }
    secure_terminal = SecureCommandLineTool()
    template_manager = EnhancedProjectTemplateManager()
    
    # --- √âquipe d'Experts V17 ---
    architect = Agent(role='Architecte Logiciel Full-Stack', tools=[template_manager], llm=llms["claude"], verbose=True, goal="Cr√©er un plan technique complet, incluant la structure et le code source initial.")
    developer = Agent(role='D√©veloppeur Full-Stack Senior', tools=[secure_terminal], llm=llms["gemini"], verbose=True, goal="Construire le projet et √©crire le code source dans les fichiers.")
    code_reviewer = Agent(role='Ing√©nieur Qualit√© Code', tools=[secure_terminal], llm=llms["openai"], verbose=True, goal="Analyser le code source g√©n√©r√© pour la qualit√© et la conformit√©.")
    functional_tester = Agent(role='Ing√©nieur QA Fonctionnel', tools=[secure_terminal], llm=llms["claude"], verbose=True, goal="Valider que l'application est fonctionnelle de bout en bout.")
    devops_engineer = Agent(role='Ing√©nieur DevOps', tools=[secure_terminal], llm=llms["claude"], verbose=True, goal="Versionner le projet valid√© avec Git.")

    # --- Pipeline "Qualit√© Totale" V17 ---
    
    # 1. Architecture
    architecture_task = Task(
        description=f"Pour le projet '{project_name}', cr√©e un plan d'action. Le plan doit inclure :\n1. Les commandes pour cr√©er le squelette via le template '{template_type}'.\n2. Le contenu complet pour un fichier `backend/server.js` exposant une route GET `/api/greeting` qui retourne `{{'message': 'Hello from AI!'}}`.\n3. Le contenu complet pour `frontend/src/App.jsx` qui fait un `fetch` √† cette API et affiche le message.",
        expected_output="Un plan d√©taill√© en plusieurs parties : commandes de setup, puis le code source pour chaque fichier.",
        agent=architect
    )

    # 2. D√©veloppement
    development_task = Task(
        description=f"Ex√©cute le plan de l'architecte pour le projet '{project_name}'. D'abord, le squelette. Ensuite, √©cris le code source dans `backend/server.js` et `frontend/src/App.jsx`.",
        expected_output="Confirmation que le squelette et les fichiers de code ont √©t√© cr√©√©s.",
        agent=developer,
        context=[architecture_task]
    )

    # 3. Revue de Code
    code_review_task = Task(
        description=f"Analyse le code des fichiers `workspace/{project_name}/backend/server.js` et `frontend/src/App.jsx`. V√©rifie la syntaxe, la logique, et la conformit√© avec le plan.",
        expected_output="Un rapport de revue de code.",
        agent=code_reviewer,
        context=[development_task]
    )

    # 4. Tests Fonctionnels
    functional_validation_task = Task(
        description=f"Effectue un test fonctionnel du projet '{project_name}'. Les √©tapes sont :\n1. D√©marre le serveur backend en arri√®re-plan : `cd workspace/{project_name}/backend && node server.js & echo $! > server.pid`\n2. Attends 5 secondes : `sleep 5`\n3. Teste l'API : `curl http://localhost:3001/api/greeting`\n4. Arr√™te le serveur : `kill $(cat workspace/{project_name}/backend/server.pid)`",
        expected_output="Le r√©sultat de la commande `curl`. Il doit contenir le message 'Hello from AI!'.",
        agent=functional_tester,
        context=[code_review_task]
    )

    # 5. Versioning Git
    git_commit_task = Task(
        description=f"Le projet a pass√© les tests. Initialise un d√©p√¥t Git pour '{project_name}', configure l'utilisateur, et cr√©e un commit initial structur√© avec un tag v1.0.0.",
        expected_output=f"Confirmation que le d√©p√¥t Git a √©t√© initialis√© pour '{project_name}'.",
        agent=devops_engineer,
        context=[functional_validation_task]
    )

    # --- Lancement ---
    crew = Crew(
        agents=[architect, developer, code_reviewer, functional_tester, devops_engineer],
        tasks=[architecture_task, development_task, code_review_task, functional_validation_task, git_commit_task],
        process=Process.sequential, verbose=2
    )
    result = crew.kickoff()

    print("\n" + "="*50 + "\nüéâ PROJET V17 FONCTIONNEL ET VERSIONN√â !\n" + "="*50)
    print("üìñ Rapport final de la mission :\n" + "="*50 + f"\n{result}")

if __name__ == "__main__":
    main()
